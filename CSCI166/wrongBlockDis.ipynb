{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Colab Jupyter Notebook for our class example w/ Block Discount World:\n",
    "\n",
    "# 5 State = {a, b, c, d, e}\n",
    "# 3 Actions = {Left, Right, Exit}\n",
    "# Exit available only in a & e.\n",
    "# Exit from a yields reward of 10\n",
    "# Exit from e yields reward of 1\n",
    "\n",
    "\n",
    "# Actions(a) = exit\n",
    "# ACtions(b) = left / right\n",
    "\n",
    "states = ['a','b', 'c', 'd', 'e']\n",
    "actions = ['left', 'right', 'exit']\n",
    "\n",
    "rewards = {\n",
    "    'a':{'exit': 10, 'left': 0, 'right': 0},\n",
    "    'e':{'exit':1, \"left\":0, 'right':0},\n",
    "    'b':{'left':0, 'right':0},\n",
    "    'c':{'left':0, 'right':0},\n",
    "    'd':{'left':0, 'right':0},\n",
    "}\n",
    "\n",
    "# Transition fucntion according to set rules\n",
    "def transition(state, action):\n",
    "    # Exit is the only aloud action in states a and e\n",
    "    if state == 'a' and action == 'exit':\n",
    "        return 'a'  # Exit state 'a'\n",
    "    if state == 'e' and action == 'exit':\n",
    "        return 'e'  # Exit state 'e'\n",
    "    # All other state transitions\n",
    "    if state=='b' and action=='left':\n",
    "        return 'a'\n",
    "    if state=='b' and action=='right':\n",
    "        return 'c'\n",
    "    if state=='c' and action=='left':\n",
    "        return 'b'\n",
    "    if state=='c' and action=='right':\n",
    "        return 'd'\n",
    "    if state=='d' and action=='left':\n",
    "        return 'c'\n",
    "    if state=='d' and action=='right':\n",
    "        return 'e'\n",
    "    # Capture all other cases\n",
    "    return 'invalid'\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Calculate Optimum Policy for cases: Transitions are deterministic, ùõæ=1, ùõæ=0.1\n",
    "\n",
    "def optimum_policy(gamma, threshold=1e-6):\n",
    "    V = {s: 0 for s in states}\n",
    "    policy = {s: None for s in states}\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for s in states:\n",
    "            action_values = []\n",
    "\n",
    "            for a in actions:\n",
    "                if a in rewards[s]:\n",
    "                    next_state = transition(s, a)\n",
    "                    if next_state == 'invalid':\n",
    "                        continue\n",
    "                    reward = rewards[s][a]\n",
    "                    value = reward + gamma * V.get(next_state, 0)\n",
    "                    action_values.append((value, a))  # Append as a tuple (value, action)\n",
    "\n",
    "            if action_values:\n",
    "                max_value, best_action = max(action_values, key=lambda x: x[0])  # Unpack the tuple\n",
    "                delta = max(delta, abs(V[s] - max_value))\n",
    "                V[s] = max_value\n",
    "                policy[s] = best_action\n",
    "\n",
    "        if delta < threshold:\n",
    "            break\n",
    "\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m gamma_01 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate value for gamma = 1\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m V_gamma_1, V_policy_1 \u001b[38;5;241m=\u001b[39m \u001b[43moptimum_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValues for gamma = 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, V_gamma_1)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate value for gamma = 0.1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 15\u001b[0m, in \u001b[0;36moptimum_policy\u001b[1;34m(gamma, threshold)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m rewards[s]:\n\u001b[1;32m---> 15\u001b[0m         next_state \u001b[38;5;241m=\u001b[39m \u001b[43mtransition\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m next_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m, in \u001b[0;36mtransition\u001b[1;34m(state, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m rewards \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m},\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m},\n\u001b[0;32m     22\u001b[0m }\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Transition fucntion according to set rules\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransition\u001b[39m(state, action):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Exit is the only aloud action in states a and e\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Exit state 'a'\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# (2) Calculate the value of the sequence of rewards from each of the states under the optimum policy for both previous cases.\n",
    "\n",
    "gamma_1 = 1.0\n",
    "gamma_01 = 0.1\n",
    "\n",
    "# Calculate value for gamma = 1\n",
    "V_gamma_1, V_policy_1 = optimum_policy(gamma_1)\n",
    "print(\"Values for gamma = 1:\", V_gamma_1)\n",
    "\n",
    "# Calculate value for gamma = 0.1\n",
    "V_gamma_01, V_Policy_2 = optimum_policy(gamma_01)\n",
    "print(\"Values for gamma = 0.1:\", V_gamma_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West and East are equally good at gamma = 0.0\n"
     ]
    }
   ],
   "source": [
    "# (2) For which gamma are West and East equally good when in state d?\n",
    "def compare_west_east(state, gamma):\n",
    "    # Calculate values for going West (Left) and East (Right) in state `d`\n",
    "    V = {s: 0 for s in states}\n",
    "    \n",
    "    next_state_west = transition(state, 'left')\n",
    "    next_state_east = transition(state, 'right')\n",
    "    \n",
    "    value_west = rewards[state]['left'] + gamma * V[next_state_west]\n",
    "    value_east = rewards[state]['right'] + gamma * V[next_state_east]\n",
    "    \n",
    "    return value_west, value_east\n",
    "\n",
    "# Now let's find the gamma for which West and East are equally good\n",
    "for gamma in np.linspace(0, 1, 100):\n",
    "    value_west, value_east = compare_west_east('d', gamma)\n",
    "    if np.isclose(value_west, value_east, atol=1e-2):\n",
    "        print(f\"West and East are equally good at gamma = {gamma}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
